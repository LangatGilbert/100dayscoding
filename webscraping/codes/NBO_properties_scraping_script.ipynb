{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Beautiful Soup will help us read the Html document\n",
    "from bs4 import BeautifulSoup as soup\n",
    "#allows you to send HTTP requests\n",
    "from requests import get\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#requesting data from url\n",
    "response = requests.get(\"https://www.buyrentkenya.com/property-for-sale?page=5000\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<!DOCTYPE html>\\n<html dir=\"ltr\" lang=\"en\" xml:lang=\"en\" xmlns=\"http://www.w3.org/1999/xhtml\">\\n<head'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text[:100] #returns the first 2000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "data = soup(response.text)\n",
    "house_containers = data.find_all(\"div\",class_= \"body-icon-control-left\")\n",
    "title = []\n",
    "for data in house_containers:\n",
    "    type_ = data.find_all('a', href=True) \n",
    "    for i in type_:\n",
    "        d = i['href']\n",
    "        res = d.split('/')[2]\n",
    "        res_1 = res.split('?')[0]\n",
    "        title.append(res_1)\n",
    "        \n",
    "print(len(title))\n",
    "# title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# title=[]\n",
    "# n_pages = 0\n",
    "# for page in range(1,9): #the no. of pages to be extracted considering the pages available in the url\n",
    "#     n_pages +=1\n",
    "#     url = 'https://www.buyrentkenya.com/property-for-sale/nairobi?'+'&page='+str(page)\n",
    "    \n",
    "#     # this for gets uns into next page after every iteration.\n",
    "#     r = requests.get(url) #here r is response data\n",
    "#     page_html = soup(r.text)\n",
    "#     house_containers = page_html.find_all(\"div\",class_= \"body-icon-control-left\")\n",
    "#     for data in house_containers:\n",
    "#         type_ = data.find_all('a', href=True) \n",
    "#         for i in type_:\n",
    "#             try:\n",
    "#                 d = i['href']\n",
    "#                 res = d.split('/')[2]\n",
    "#                 res_1 = res.split('?')[0]\n",
    "#                 title.append(res_1)\n",
    "#             except:\n",
    "#                 title.append('None')\n",
    "\n",
    "# print(len(title))\n",
    "# title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price_per_sqft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list for appending the extracted value\n",
    "title = []\n",
    "location = []\n",
    "price = []\n",
    "price_per_sqft = []\n",
    "agent = []\n",
    "web_link = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_pages = 0\n",
    "for page in range(1,5000): #the no. of pages to be extracted considering the pages available in the url\n",
    "    n_pages +=1\n",
    "    url = 'https://www.buyrentkenya.com/property-for-sale?'+'&page='+str(page)\n",
    "    \n",
    "    # this for gets uns into next page after every iteration.\n",
    "    r = requests.get(url) #here r is response data\n",
    "    page_html = soup(r.text)\n",
    "    house_containers = page_html.find_all('div', class_ = 'item-body table-cell')# class containing overall data of a property\n",
    "    \n",
    "    ##### title\n",
    "    for data in house_containers:\n",
    "        type_ = data.find_all(\"h2\", class_=\"property-title\") \n",
    "        for i in type_:\n",
    "            d = i.text\n",
    "            title.append(d)\n",
    "            \n",
    "    ########Location \n",
    "        location_ = data.find_all(\"div\", class_ = \"property-location\")\n",
    "        for i in location_:\n",
    "            d = i.text\n",
    "            r= d.split(',',)[0]#splitting the obtained text and returning the first element of text\n",
    "            location.append(r)\n",
    "            \n",
    "            \n",
    "    ##########price\n",
    "        cost = data.find_all(\"div\", class_ = \"info-row price\")\n",
    "        for i in cost:\n",
    "            d= i.text\n",
    "            if 'KES' in d:\n",
    "                a = d.split()[1]\n",
    "                r = re.sub(\",\",\"\",a)\n",
    "                price.append(r)\n",
    "            else:\n",
    "                e = 0\n",
    "                price.append(e)\n",
    "     \n",
    "                \n",
    "    ####### price per sqft\n",
    "    \n",
    "        rate_sqft = data.find_all('a', class_=\"item-sub-price\")\n",
    "        for i in rate_sqft:\n",
    "            d = i.text\n",
    "            if 'KES' in d:\n",
    "                res = d.split('/')[0]\n",
    "                r = re.sub(\",\",\"\",res)\n",
    "                price_per_sqft.append(r)\n",
    "\n",
    "            else :\n",
    "                e = 0\n",
    "                price_per_sqft.append(e)  \n",
    "\n",
    "print('You scraped {} pages containing {} properties.'.format(n_pages, len(title)))\n",
    "# Returns the number of pages scrapped and time taken for scarpping those pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_pages = 0\n",
    "for page in range(1,5000): #the no. of pages to be extracted considering the pages available in the url\n",
    "    n_pages +=1\n",
    "    url = 'https://www.buyrentkenya.com/property-for-sale?'+'&page='+str(page)\n",
    "    \n",
    "    # this for gets uns into next page after every iteration.\n",
    "    r = requests.get(url) #here r is response data\n",
    "    page_html = soup(r.text)\n",
    "    house_containers = page_html.find_all(\"div\",class_= \"body-icon-control-left\")# class containing overall data of a property\n",
    "    \n",
    "    ##### title\n",
    "    for data in house_containers:\n",
    "        type_ = data.find_all('a', href=True) \n",
    "        for i in type_:\n",
    "            d = i['href']\n",
    "            res = d.split('/')[2]\n",
    "            res_1 = res.split('?')[0]\n",
    "            agent.append(res_1)\n",
    "            \n",
    "print('You scraped {} pages containing {} properties.'.format(n_pages, len(agent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = title\n",
    "df['location'] = location\n",
    "df['price'] = price\n",
    "df['agent'] = agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].map(lambda x: x.lstrip('\\n').rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('all_properties_data.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
